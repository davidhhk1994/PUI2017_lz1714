{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Skeleton of Assignment 4:\n",
    "    test if the distribution of \n",
    "    \n",
    "    1) trip duration of bikers that ride during the day vs night\n",
    "    \n",
    "    2) age of bikers for trips originating in Manhattan and in Brooklyn\n",
    "    \n",
    "    are different. Use 3 tests: KS, Pearson's, Spearman's. \n",
    "    \n",
    "    Use the scipy.stats functions scipy.stats.ks_2samp, scipy.stats.pearsonr, scipy.stats.spearmanr. \n",
    "    \n",
    "    For the KS do the test with the entire dataset and with a subset 200 times smaller\n",
    "    \n",
    "    Choose a single significant threshold for the whole exercise. \n",
    "    \n",
    "    For each test phrase the Null Hypothesis in words.\n",
    "    \n",
    "    Describe the return of the scipy function you use in each case.\n",
    "    \n",
    "    State the result in terms of rejection of the Null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:06.390950",
     "start_time": "2017-10-05T16:48:04.815178"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#imports downloader\n",
    "from getCitiBikeCSV import getCitiBikeCSV\n",
    "from __future__  import print_function\n",
    "\n",
    "import os\n",
    "#import for location process\n",
    "import shapely.geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Read in data\n",
    "I am reading in data from January 2015 with the function that I created getCitiBikeCSV. You are requested to use 2 months at least. It would be a good idea to use data from a colder and a warmer months, since there are more riders in the warm weather and ridership patterns may change with weather, temperature, etc. You should use data from multiple months, joining multiple datasets (thus addressing some systematic errors as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:09.386484",
     "start_time": "2017-10-05T16:48:06.821336"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 201501\n",
      "file in place, you can continue\n",
      "Downloading 201508\n",
      "file in place, you can continue\n"
     ]
    }
   ],
   "source": [
    "#download file of 2 months. one is colder, the other is warmer.\n",
    "timeList = ['201501', '201508']\n",
    "for datestring in enumerate (timeList):\n",
    "    getCitiBikeCSV(datestring[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:11.528975",
     "start_time": "2017-10-05T16:48:10.267002"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(os.getenv(\"PUIDATA\") + \"/\" + '201501' + '-citibike-tripdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.read_csv(os.getenv(\"PUIDATA\") + \"/\" + '201508' + '-citibike-tripdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration               1464596\n",
       "starttime                  1464596\n",
       "stoptime                   1464596\n",
       "start station id           1464596\n",
       "start station name         1464596\n",
       "start station latitude     1464596\n",
       "start station longitude    1464596\n",
       "end station id             1464596\n",
       "end station name           1464596\n",
       "end station latitude       1464596\n",
       "end station longitude      1464596\n",
       "bikeid                     1464596\n",
       "usertype                   1464596\n",
       "birth year                 1237967\n",
       "gender                     1464596\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([df1, df8], join='inner')\n",
    "result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1346</td>\n",
       "      <td>1/1/2015 0:01</td>\n",
       "      <td>1/1/2015 0:24</td>\n",
       "      <td>455</td>\n",
       "      <td>1 Ave &amp; E 44 St</td>\n",
       "      <td>40.750020</td>\n",
       "      <td>-73.969053</td>\n",
       "      <td>265</td>\n",
       "      <td>Stanton St &amp; Chrystie St</td>\n",
       "      <td>40.722293</td>\n",
       "      <td>-73.991475</td>\n",
       "      <td>18660</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363</td>\n",
       "      <td>1/1/2015 0:02</td>\n",
       "      <td>1/1/2015 0:08</td>\n",
       "      <td>434</td>\n",
       "      <td>9 Ave &amp; W 18 St</td>\n",
       "      <td>40.743174</td>\n",
       "      <td>-74.003664</td>\n",
       "      <td>482</td>\n",
       "      <td>W 15 St &amp; 7 Ave</td>\n",
       "      <td>40.739355</td>\n",
       "      <td>-73.999318</td>\n",
       "      <td>16085</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>346</td>\n",
       "      <td>1/1/2015 0:04</td>\n",
       "      <td>1/1/2015 0:10</td>\n",
       "      <td>491</td>\n",
       "      <td>E 24 St &amp; Park Ave S</td>\n",
       "      <td>40.740964</td>\n",
       "      <td>-73.986022</td>\n",
       "      <td>505</td>\n",
       "      <td>6 Ave &amp; W 33 St</td>\n",
       "      <td>40.749013</td>\n",
       "      <td>-73.988484</td>\n",
       "      <td>20845</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>1/1/2015 0:04</td>\n",
       "      <td>1/1/2015 0:07</td>\n",
       "      <td>384</td>\n",
       "      <td>Fulton St &amp; Waverly Ave</td>\n",
       "      <td>40.683178</td>\n",
       "      <td>-73.965964</td>\n",
       "      <td>399</td>\n",
       "      <td>Lafayette Ave &amp; St James Pl</td>\n",
       "      <td>40.688515</td>\n",
       "      <td>-73.964763</td>\n",
       "      <td>19610</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>969</td>\n",
       "      <td>1/1/2015 0:05</td>\n",
       "      <td>1/1/2015 0:21</td>\n",
       "      <td>474</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>40.745168</td>\n",
       "      <td>-73.986831</td>\n",
       "      <td>432</td>\n",
       "      <td>E 7 St &amp; Avenue A</td>\n",
       "      <td>40.726218</td>\n",
       "      <td>-73.983799</td>\n",
       "      <td>20197</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration      starttime       stoptime  start station id  \\\n",
       "0          1346  1/1/2015 0:01  1/1/2015 0:24               455   \n",
       "1           363  1/1/2015 0:02  1/1/2015 0:08               434   \n",
       "2           346  1/1/2015 0:04  1/1/2015 0:10               491   \n",
       "3           182  1/1/2015 0:04  1/1/2015 0:07               384   \n",
       "4           969  1/1/2015 0:05  1/1/2015 0:21               474   \n",
       "\n",
       "        start station name  start station latitude  start station longitude  \\\n",
       "0          1 Ave & E 44 St               40.750020               -73.969053   \n",
       "1          9 Ave & W 18 St               40.743174               -74.003664   \n",
       "2     E 24 St & Park Ave S               40.740964               -73.986022   \n",
       "3  Fulton St & Waverly Ave               40.683178               -73.965964   \n",
       "4          5 Ave & E 29 St               40.745168               -73.986831   \n",
       "\n",
       "   end station id             end station name  end station latitude  \\\n",
       "0             265     Stanton St & Chrystie St             40.722293   \n",
       "1             482              W 15 St & 7 Ave             40.739355   \n",
       "2             505              6 Ave & W 33 St             40.749013   \n",
       "3             399  Lafayette Ave & St James Pl             40.688515   \n",
       "4             432            E 7 St & Avenue A             40.726218   \n",
       "\n",
       "   end station longitude  bikeid    usertype  birth year  gender  \n",
       "0             -73.991475   18660  Subscriber      1960.0       2  \n",
       "1             -73.999318   16085  Subscriber      1963.0       1  \n",
       "2             -73.988484   20845  Subscriber      1974.0       1  \n",
       "3             -73.964763   19610  Subscriber      1969.0       1  \n",
       "4             -73.983799   20197  Subscriber      1977.0       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tripduration', 'starttime', 'stoptime', 'start station id',\n",
       "       'start station name', 'start station latitude',\n",
       "       'start station longitude', 'end station id', 'end station name',\n",
       "       'end station latitude', 'end station longitude', 'bikeid', 'usertype',\n",
       "       'birth year', 'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(['stoptime', 'start station id', 'start station name', 'end station id', 'end station name',\n",
    "       'end station latitude', 'end station longitude', 'bikeid', 'usertype', 'gender'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:51:52.008367",
     "start_time": "2017-10-05T16:48:18.977948"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# df is the dataframe where the content of the csv file is stored\n",
    "df1['date'] = pd.to_datetime(df['starttime'])\n",
    "# note that with dataframes I can refer to variables as dictionary keys, \n",
    "# i.e. df['starttime'] or as attributes: df.starttime. \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# SPLIT BY CATEGORY\n",
    "\n",
    "as an example I am splitting data by gender and looking at age or riders:\n",
    "\n",
    "**H0: there is no statistical difference in the age distribution of male and female riders**\n",
    "$$ \\alpha = 0.05 $$\n",
    "\n",
    "extracting the age happens in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:51:52.357332",
     "start_time": "2017-10-05T16:51:52.017199"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#df is the dataframe where the content of the csv file is stored\n",
    "df['ageM'] = 2015 - df['birth year'][(df['usertype'] == 'Subscriber') & (df['gender'] == 1)]\n",
    "df['ageF'] = 2015 - df['birth year'][(df['usertype'] == 'Subscriber') & (df['gender'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#dropping some data I no longer need\n",
    "#... your code here...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:55:03.392271",
     "start_time": "2017-10-05T16:55:02.902521"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#your df should look something like this\n",
    "# look at these data carefully... you may see someinteresting values!\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:55:05.649685",
     "start_time": "2017-10-05T16:55:05.635796"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# dropping NaN values\n",
    "df['ageM'].dropna(inplace= True)\n",
    "df['ageF'].dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "lets split age in 10 year bins. the dataset is very large, so i could be split in smaller bins, but I will chose 10 years in the interest of time. \n",
    "the bin size choice should be a balance between properly sample the age space, have enough counts in each bin that the statistical noise is not significant (remember that is > sqrt(N)!) and the computational requirement to computatinal facilities ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "the next several steps are needed if you want to code up the KS test from scratch. that is for extra credit, so if you do not want to do it you may not need to plot split the distribution in bins and create the cumulative HOWEVER it is a great idea to do it anyways to explore your data viaually! remember Ascombe's quartet!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:55:21.602238",
     "start_time": "2017-10-05T16:55:20.487384"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plotting histogramswith pandas is a bitdifferent than with pylab\n",
    "# this is a VERY USEFUL syntaxfor you to knonw!\n",
    "bins = np.arange(10, 99, 5)\n",
    "axM = df.ageM.groupby(pd.cut(df.ageM, bins)).agg([count_nonzero]).plot(kind='bar', \n",
    "                                                                legend=False)\n",
    "axM.set_title(\"male riders\")\n",
    "axF = df.ageF.groupby(pd.cut(df.ageF, bins)).agg([count_nonzero]).plot(kind='bar',\n",
    "                                                                legend=False)\n",
    "axF.set_title(\"female riders\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Figure 1: histogrammed distribution of riders' ages by gender **\n",
    "here is where you should have a nice caption that describes what I am looking at, why I am looking at it, and what I should notice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "this is how the cumulative distributions look like.  Notice that i am normalizing them! if i want to reat an observed distribution like a probablility distribution i have to normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print df.ageS, df.ageS.cumsum()\n",
    "\n",
    "csM=df.ageM.groupby(pd.cut(df.ageM, bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "csF=df.ageF.groupby(pd.cut(df.ageF, bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "print (np.abs(csM / csM.max()-csF / csF.max()))\n",
    "\n",
    "plt.plot(bins[:-1] + 5, csM / csM.max(), label = \"M\")\n",
    "plt.plot(bins[:-1] + 5, csF / csF.max(), label = \"F\")\n",
    "plt.plot(bins[:-1] + 5, np.sqrt(csF / csF.max() - csM / csM.max())**2, 'k-',\n",
    "        label = \"difference\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Normalized Cumulative Number\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "** Figure 2: the cumulative distribution of CitiBike riders' ages by gender** ... [a good caption here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "They look similar! But the difference gets to 10%. If I wanted to code the KS test by hand I woud have everything I need: the normalized cumulative distributions can be subtracted from each other and the max distance can calculated. \n",
    "\n",
    "Notice that there may be NaN values you are gonna have to deal with! \n",
    "You can do that for example with a Boolean statementsuch as  df.ageF[~np.isnan(df.ageF)] or you can use numpy functions that deal with Nan values: nansum, nanmean, nanstd..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "lets run the scipy KS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:02.949986",
     "start_time": "2017-10-05T16:58:02.443596"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "#remember that your imports should all be at the top. I leave it here to hightlight that this package is needed at this point of the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# KS tests to compare 2 samples\n",
    "\n",
    "http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ks_2samp.html\n",
    "\n",
    "the KS test in scipy returns the p-value BUT make sure you understand what the NULL is! read the documentation carefully! what is the null hypothesis that you can/cannot reject?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:13.968035",
     "start_time": "2017-10-05T16:58:13.899033"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ks = scipy.stats.ks_2samp(df.ageM, df.ageF)\n",
    "#print (ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**  FILL IN THE CELL BELOW!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:24.751556",
     "start_time": "2017-10-05T16:58:24.747653"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## your words here!...\n",
    "## this cell is for you to tell me what the scipy KS test returned and what it means in terms of NULL HYPOTHESIS\n",
    "## to do that refer to the scipy documentation to understand the output of the scipy.stats.ks_2samp function\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "The scipy.stats KS test already tells me the significance and the p-value. \n",
    "\n",
    "The next few cells are here just to show you how you would obtain the same result by hand, but they are **not required**. \n",
    "\n",
    "Remember: the Null hypothesis is rejected if \n",
    "\n",
    "$D_KS(n1,n2) > c(\\alpha) \\sqrt{\\frac{(n1 + n2)}{n1n2}}$\n",
    "\n",
    "(see class notes) where $c(\\alpha$) is the inverse of the KS distribution, and you do not have to know how to get that cause there are tables that list critical values!! \n",
    "\n",
    "http://www.real-statistics.com/tests-normality-and-symmetry/statistical-tests-normality-symmetry/kolmogorov-smirnov-test/kolmogorov-distribution/\n",
    "\n",
    "But also this result depends in your choice of binning through, and thustheresultyou get by hand may not be exactly the same as the one the KS returns. Either way: this is how you would calculate the KS statistics by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:33.858841",
     "start_time": "2017-10-05T16:58:33.850240"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#here is the critical values tablel. Have you chosen your significance level yet?? you should do it first thing!\n",
    "from IPython.display import Image\n",
    "Image(filename=\"../plotsforclasses/ks2sample_table.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:45.489436",
     "start_time": "2017-10-05T16:58:45.483526"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## your words here!...\n",
    "## this cell is for you to redo the test with reducted dataset \n",
    "## and tell me what the scipy ks test returned and what it means in terms of NULL HYPOTHESIS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Now retest using a test for correlation. \n",
    "\n",
    "That will answer a slightly different question though - formulate the NULL appropriately. The tests for correlations (generally) requires the variable to be paired, so that I can tell if x changes does y change similarly. But the datasets are of different size! You will need to reduce them to the same size. You can do that by subsampling of the data: take only 1 ride every of 200, which you can achieve \"slicing and broadcasting\" the array or using one of the python function (built in python numpy.random.choice() functions for example: Docstring:\n",
    "choice(a, size=None, replace=True, p=None)\n",
    "\n",
    "Generates a random sample from a given 1-D array\n",
    "\n",
    "        .. versionadded:: 1.7.0\n",
    "\n",
    "Parameters\n",
    "...\n",
    "\n",
    "But make sure you understand how to use it! there is an option \"replace\" which you should think about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Pearson's  test for correlation\n",
    "\n",
    "** notice that the Pearson's is a pairwise test: the samples need to be **\n",
    " a. the same size\n",
    " b. sorted! (how??)\n",
    "    \n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:05:04.485128",
     "start_time": "2017-10-05T17:05:04.480928"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here!\n",
    "# wrangle the data as needed\n",
    "# please perform the Pearson's test \n",
    "# and tell me what you find in terms of NULL hypothesis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Spearman's  test for correlation\n",
    "\n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html#scipy.stats.spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:05:09.530148",
     "start_time": "2017-10-05T17:05:09.525214"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here!\n",
    "# wrangle the data as needed\n",
    "# please perform the Spearman's test and tell me what you find in terms of NULL hypothesis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "** please comment on the numbers that you get in the light of the scipy manual: what is rerutned? what does it mean??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "135px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
